# -*- coding: utf-8 -*-
"""NLP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zJyIP5jfzW1-OnRJNx7VxwAv7In57bni
"""

import pandas as pd
import numpy as np

df=pd.read_csv('/content/BBC News Train.csv')



df.head()

column_names = df.columns.tolist()
column_names

unique_categories = df['Category'].unique()
unique_categories

import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

stop_words = set(stopwords.words('english'))

import string
import re

df['Text'] = df['Text'].str.lower()
df['Category'] = df['Category'].str.lower()

df[['Text','Category']].head()

df[['Text', 'Category']] = df[['Text', 'Category']].applymap(lambda x: re.sub(r'[^\w\s]', '', str(x)))
df[['Text', 'Category']] = df[['Text', 'Category']].applymap(lambda x: re.sub(r'\d+', '', str(x)))
df[['Text', 'Category']] = df[['Text', 'Category']].applymap(lambda x: re.sub(r'\s+', ' ', str(x)))

df[['Text', 'Category']].head()

def simple_tokenizer(text):
    tokens = text.split()
    tokens = [word for word in tokens if word not in stop_words]
    return tokens

df['Text'] = df['Text'].apply(simple_tokenizer)

from nltk.stem import PorterStemmer, WordNetLemmatizer

lemmatizer = WordNetLemmatizer()
Stemmer = PorterStemmer()

df['Text'] = df['Text'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])

df['Text']

df['Text'] = df['Text'].apply(lambda x: [Stemmer.stem(word) for word in x])



df['Text'] = df['Text'].apply(lambda x: ' '.join(x))

from sklearn.feature_extraction.text import CountVectorizer

vectorizer_unigram = CountVectorizer(ngram_range=(1, 1))
vectorizer_bigram = CountVectorizer(ngram_range=(1, 2))
vectorizer_trigram = CountVectorizer(ngram_range=(1, 3))

X_unigram = vectorizer_unigram.fit_transform(df['Text'])
X_bigram = vectorizer_bigram.fit_transform(df['Text'])
X_trigram = vectorizer_trigram.fit_transform(df['Text'])

X_unigram.shape, X_bigram.shape, X_trigram.shape

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X_bigram, df['Category'], test_size=0.2, random_state=42)

from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

nb_classifier = MultinomialNB()
nb_classifier.fit(X_train, y_train)

y_pred_nb = nb_classifier.predict(X_test)

accuracy_nb = accuracy_score(y_test, y_pred_nb)
precision_nb = precision_score(y_test, y_pred_nb, average='weighted')
recall_nb = recall_score(y_test, y_pred_nb, average='weighted')
f1_nb = f1_score(y_test, y_pred_nb, average='weighted')

nb_report = {
    "accuracy": accuracy_nb,
    "precision": precision_nb,
    "recall": recall_nb,
    "f1_score": f1_nb
}

nb_report

lr_classifier = LogisticRegression(max_iter=1000)
lr_classifier.fit(X_train, y_train)

y_pred_lr = lr_classifier.predict(X_test)

accuracy_lr = accuracy_score(y_test, y_pred_lr)
precision_lr = precision_score(y_test, y_pred_lr, average='weighted')
recall_lr = recall_score(y_test, y_pred_lr, average='weighted')
f1_lr = f1_score(y_test, y_pred_lr, average='weighted')

lr_report = {
    "accuracy": accuracy_lr,
    "precision": precision_lr,
    "recall": recall_lr,
    "f1_score": f1_lr
}

lr_report

combined_report = {
    "Naive Bayes": nb_report,
    "Logistic Regression": lr_report
}
combined_report

import matplotlib.pyplot as plt

metrics = ["accuracy", "precision", "recall", "f1_score"]
nb_values = [combined_report["Naive Bayes"][metric] for metric in metrics]
lr_values = [combined_report["Logistic Regression"][metric] for metric in metrics]

fig, ax = plt.subplots(figsize=(10, 6))
bar_width = 0.35
index = range(len(metrics))
bar1 = plt.bar(index, nb_values, bar_width, label='Naive Bayes')
bar2 = plt.bar([i + bar_width for i in index], lr_values, bar_width, label='Logistic Regression')
plt.xlabel('Metrics')
plt.ylabel('Scores')
plt.title('Model Performance Comparison')
plt.xticks([i + bar_width / 2 for i in index], metrics)
plt.legend()

plt.tight_layout()
plt.show()

def classify_news(model, vectorizer, text):

    text = text.lower()
    text = re.sub(r'[^\w\s]', '', text)
    text = re.sub(r'\d+', '', text)
    text = re.sub(r'\s+', ' ', text)
 tokens = simple_tokenizer(text)
   text = ' '.join(tokens)
     text_vect = vectorizer.transform([text]
   prediction = model.predict(text_vect)
    return prediction[0]

message = input("Enter the message to classify: ")
nb_prediction = classify_news(nb_classifier, vectorizer_bigram, message)
lr_prediction = classify_news(lr_classifier, vectorizer_bigram, message)

print("Naive Bayes Prediction:", nb_prediction)
print("Logistic Regression Prediction:", lr_prediction)

